{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aec8abd-5a05-4e8d-9962-93caf36e6cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e147f8c-af89-411c-ab96-43b1811b4b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_mp4_from_youtube(url):\n",
    "    # Set the options for the download\n",
    "    filename = 'infoslack.mp4'\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "        'outtmpl': filename,\n",
    "        'quiet': True,\n",
    "    }\n",
    "\n",
    "    # Download the video file\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(url, download=True)\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=qN_2fnOPY-M\"\n",
    "download_mp4_from_youtube(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd1ca7c-2057-41fe-b497-7be6ee10821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=iw2TeYESnTk\n",
      "[youtube] iw2TeYESnTk: Downloading webpage\n",
      "[youtube] iw2TeYESnTk: Downloading ios player API JSON\n",
      "[youtube] iw2TeYESnTk: Downloading android player API JSON\n",
      "[youtube] iw2TeYESnTk: Downloading m3u8 information\n",
      "[info] iw2TeYESnTk: Downloading 1 format(s): 251\n",
      "[download] Destination: infoslack-audio\n",
      "[download] 100% of   10.89MiB in 00:00:00 at 18.48MiB/s    \n",
      "[ExtractAudio] Destination: infoslack-audio.mp3\n",
      "Deleting original file infoslack-audio (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "# refatorando para extrair somente o áudio\n",
    "def download_audio(url):\n",
    "    \n",
    "    filename = 'infoslack-audio'\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio',\n",
    "        'postprocessors':[{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '128',\n",
    "        }],\n",
    "        'outtmpl': filename,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(url, download=True)\n",
    "        \n",
    "download_audio(\"https://www.youtube.com/watch?v=iw2TeYESnTk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe17ecc6-5208-49d7-ba88-4f32631203a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper local\n",
    "import whisper\n",
    "\n",
    "#model = whisper.load_model(\"base\")\n",
    "#result = model.transcribe(\"lecuninterview.mp4\")\n",
    "#print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd476041-e4ef-4e06-a429-037e0f140f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"infoslack-audio.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    response_format=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5962d3c9-2660-4d0e-a287-f44c575e1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a97832b-50bd-4bb3-aea5-3bef974c4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text.txt', 'w') as file:  \n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2a1242-795b-4dde-a231-1adf073dd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3946b7-d041-4520-9d3f-85bb249675eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68af10b-09f1-40f5-a7b6-c8a757f5e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "with open('text.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "texts = text_splitter.split_text(text)\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad1efe2-9d61-4fbe-b05d-7cf0484c00ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Word Embeddings são uma forma de representar palavras e textos como vetores numéricos. E a coisa mais interessante sobre esse conceito é que quando você pega palavras ou frases e converte em uma representação numérica, palavras que são numericamente semelhantes são semelhantes em significado também. E isso nos permite construir coisas como um mecanismo de busca com um nível de precisão interessante. Nesse vídeo vamos explorar um sistema de busca semântico usando Embeddings da OpenAI. Então, como funciona esse mecanismo de busca? Como pegar essas palavras e frases, converter em números para realizar classificação, detecção de anomalias, agrupamento, enfim, todas essas tarefas legais de linguagem natural? Bem, eu preparei esse exemplo sobre Embeddings de palavras e agora vamos ver como tudo isso funciona. Há matemática por trás, de uma maneira que você possa entender e aplicar. Eu vou deixar um link desse projeto na descrição. Bem, a primeira coisa que precisamos fazer é instalar o')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1fe6bf-e603-486a-901f-01041456a4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  This article explains how to use OpenAI's Word Embeddings to convert words and phrases into\n",
      "numeric vectors, allowing for the creation of semantic search systems. It also discusses the\n",
      "challenges of using these models in companies with large amounts of data and users with specific\n",
      "intentions. The article suggests using a model of hallucination to provide satisfactory responses to\n",
      "questions, with a knowledge base on specific domains, Vector Database as a pinecone, and well-\n",
      "designed queries and prompts.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833d70aa-fd4e-4c7a-9937-056309dc3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print( chain.llm_chain.prompt.template )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3009a1a4-1dff-4a44-ac4e-96c05d8d8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise bullet point summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONSCISE SUMMARY IN BULLET POINTS:\"\"\"\n",
    "\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template, \n",
    "                        input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18dfdd77-55ff-44a2-8336-a54052f2892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Word Embeddings is a way to represent words and texts as numerical vectors.\n",
      "- Words that are numerically similar are also similar in meaning.\n",
      "- OpenAI Embeddings can be used to build a semantic search engine.\n",
      "- Steps include installing OpenAI package, importing Python packages, configuring API key, and loading CSV file into a pandas dataframe.\n",
      "- GetEmbedding function is used to convert words into vectors.\n",
      "- Lambda function is used to apply GetEmbedding to each element in the dataframe column.\n",
      "- Vector of a search term (e.g. Caputino) can be used to find similarity in numerical representations.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"stuff\", \n",
    "                             prompt=BULLET_POINT_PROMPT)\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "\n",
    "wrapped_text = textwrap.fill(output_summary, \n",
    "                             width=1000,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50603758-d4a3-4d8d-8ba9-4e4136df486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Word Embeddings são uma forma de representar palavras e textos como vetores numéricos, permitindo\n",
      "a construção de mecanismos de busca com um nível de precisão interessante. Neste vídeo, exploramos\n",
      "um sistema de busca semântico usando Embeddings da OpenAI, mostrando como pegar palavras e frases,\n",
      "converter em números e realizar tarefas de linguagem natural. Usando o pacote da OpenAI, importamos\n",
      "os pacotes Python necessários, como o pandas e numpy. Configuramos a chave de API da OpenAI e\n",
      "carregamos um arquivo CSV de palavras em um dataframe do pandas. Em seguida, calculamos os\n",
      "Embeddings das palavras, o que significa converter essas palavras em vetores usando a OpenAI. Ao\n",
      "enviar uma requisição para a API com uma palavra, como retorno recebemos um modelo\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7145807f-c480-43e3-a792-ce316cc7639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Word Embeddings são uma forma de representar palavras e textos como vetores numéricos. E a coisa mais interessante sobre esse conceito é que quando você pega palavras ou frases e converte em uma representação numérica, palavras que são numericamente semelhantes são semelhantes em significado também. E isso nos permite construir coisas como um mecanismo de busca com um nível de precisão interessante. Nesse vídeo vamos explorar um sistema de busca semântico usando Embeddings da OpenAI. Então, como funciona esse mecanismo de busca? Como pegar essas palavras e frases, converter em números para realizar classificação, detecção de anomalias, agrupamento, enfim, todas essas tarefas legais de linguagem natural? Bem, eu preparei esse exemplo sobre Embeddings de palavras e agora vamos ver como tudo isso funciona. Há matemática por trás, de uma maneira que você possa entender e aplicar. Eu vou deixar um link desse projeto na descrição. Bem, a primeira coisa que precisamos fazer é instalar o')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57acd138-65c8-4fce-86ad-eb3636c9d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.environ.get('PINECONE_ENV')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c82b4df2-b952-47b4-b2bf-b283e64d0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e03ffad2-7527-4ee0-8ec4-653b7b14f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"linuxtips\"\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07f15e99-527c-4d94-a93a-87b0fe803066",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([d.page_content for d in docs], embeddings, index_name=index_name, namespace='extras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5434a191-a9d3-4f47-8851-a15860aee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "query = \"o que são word embeddings?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e8755c1-411f-4f89-ad32-26641bb037d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Word Embeddings são uma forma de representar palavras e textos como vetores numéricos. E a coisa mais interessante sobre esse conceito é que quando você pega palavras ou frases e converte em uma representação numérica, palavras que são numericamente semelhantes são semelhantes em significado também. E isso nos permite construir coisas como um mecanismo de busca com um nível de precisão interessante. Nesse vídeo vamos explorar um sistema de busca semântico usando Embeddings da OpenAI. Então, como funciona esse mecanismo de busca? Como pegar essas palavras e frases, converter em números para realizar classificação, detecção de anomalias, agrupamento, enfim, todas essas tarefas legais de linguagem natural? Bem, eu preparei esse exemplo sobre Embeddings de palavras e agora vamos ver como tudo isso funciona. Há matemática por trás, de uma maneira que você possa entender e aplicar. Eu vou deixar um link desse projeto na descrição. Bem, a primeira coisa que precisamos fazer é instalar o')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "787775c9-0e0e-4c76-8061-43d5fc0a6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type='similarity', search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c4c2a8a-cc9e-49e2-8279-a3dda4f83c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Use as seguintes transcrições para responder à pergunta em formato de bullet points e de forma resumida. Se não souber a resposta, diga apenas que não sabe, não tente inventar uma resposta.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Resposta resumida em bullter points:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ce1f6e3-96af-4e93-b039-daee0e20249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word embeddings são uma forma de representar palavras e textos como vetores numéricos, onde palavras numericamente semelhantes são semelhantes em significado também. Isso permite construir mecanismos de busca com um nível de precisão interessante.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever)\n",
    "\n",
    "print( qa.run(\"Resuma word embeddings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ed354-4516-4843-806d-b960eca62a4d",
   "metadata": {},
   "source": [
    "### Refazendo com GPT-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3e78ded-dc71-4b07-a3bc-d835a173f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-1106-preview', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80e00449-af4c-4e11-8061-a117d426aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "    Use as seguintes transcrições para responder à pergunta em formato de bullet points e de forma \n",
    "    resumida. Se não souber a resposta, diga apenas que não sabe, não tente inventar uma resposta.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    Resposta resumida em bullter points:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "566c91c5-3c8b-4e50-a189-d12629ffaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efe38b1b-4f00-464e-95d6-614b11731f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Word Embeddings são representações vetoriais de palavras e textos.\\n- Palavras com significados semelhantes têm representações numéricas próximas.\\n- Essas representações permitem realizar tarefas de processamento de linguagem natural como classificação e agrupamento.\\n- Embeddings podem ser obtidos através de APIs ou pacotes, como o da OpenAI.\\n- Modelos como o ada002 da OpenAI podem ser usados para converter palavras em vetores.\\n- Vetores de palavras podem ser armazenados em bancos de dados de vetores para consultas por similaridade.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Resuma word embeddings\"\n",
    "docs = docsearch.similarity_search(query, k=3, namespace='extras')\n",
    "context = docs[0].page_content + docs[1].page_content + docs[2].page_content\n",
    "res = LLMChain(prompt=prompt, llm=llm)\n",
    "res.run(query=query, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059ea07-9149-4099-996c-a87deeba962f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
